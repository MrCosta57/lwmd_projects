{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import words\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "#nltk.download('words')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "data_dir=\"datasets/\"\n",
    "dataset_name_dir=\"nfcorpus/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=pd.read_json(data_dir+dataset_name_dir+\"corpus.jsonl\", lines=True)\n",
    "queries=pd.read_json(data_dir+dataset_name_dir+\"queries.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sparse_repr(vocab: np.array, corpus: pd.DataFrame, queries: pd.DataFrame):\n",
    "    doc_tfidf=TfidfVectorizer(lowercase=True, vocabulary=vocab, stop_words=None, token_pattern=r'\\w+')\n",
    "    q_counter=CountVectorizer(lowercase=True, vocabulary=vocab, stop_words=None, token_pattern=r'\\w+')\n",
    "\n",
    "    sparse_doc=doc_tfidf.fit_transform(corpus[\"text\"])\n",
    "    sparse_q=q_counter.fit_transform(queries[\"text\"])\n",
    "\n",
    "    return sparse_doc, sparse_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=np.unique(np.char.lower(words.words()))\n",
    "sparse_doc, sparse_q=compute_sparse_repr(vocab, corpus, queries)\n",
    "\n",
    "#Here it's basically computed sparse_score=<q_sparse, d_sparse>\n",
    "sparse_score_df=pd.DataFrame(np.dot(sparse_q, sparse_doc.transpose()).toarray(), index=queries[\"_id\"], columns=corpus[\"_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dense_repr(corpus: pd.DataFrame, queries: pd.DataFrame):\n",
    "    transformers = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    dense_c=transformers.encode(corpus[\"text\"], convert_to_numpy = True)\n",
    "    dense_q=transformers.encode(queries[\"text\"], convert_to_numpy = True)\n",
    "    \n",
    "    return dense_c, dense_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_c, dense_q=compute_dense_repr(corpus, queries)\n",
    "\n",
    "#Here it's basically computed dense_score=<q_dense, d_dense>\n",
    "dense_score_df=pd.DataFrame(np.dot(dense_q, dense_c.transpose()), index=queries[\"_id\"], columns=corpus[\"_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_score_df.to_parquet(\"sparse_score_df_nfcorpus.parquet\")\n",
    "dense_score_df.to_parquet(\"dense_score_dfnfcorpus.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top k retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_score_df=pd.read_parquet(\"sparse_score_df_nfcorpus.parquet\")\n",
    "dense_score_df=pd.read_parquet(\"dense_score_dfnfcorpus.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_exact_retrieval(sparse_score_df: pd.DataFrame, dense_score_df: pd.DataFrame, k: int):\n",
    "    total_score_df=sparse_score_df+dense_score_df\n",
    "\n",
    "    idx_exact_top_k=np.argsort(total_score_df)[:, :-k-1:-1]\n",
    "    top_k_exact_docs=np.array(total_score_df.columns[idx_exact_top_k.reshape(-1)]).reshape(-1, k)\n",
    "\n",
    "    return total_score_df, top_k_exact_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5\n",
    "total_score_df, top_k_exact_docs=compute_exact_retrieval(sparse_score_df, dense_score_df, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top k' retrieval (approximate case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_approx_retrieval(sparse_score_df: pd.DataFrame, dense_score_df: pd.DataFrame, total_score_df: pd.DataFrame, k_prime: int):\n",
    "    idx_sparse_scores=np.argsort(sparse_score_df)[:, :-k_prime-1:-1]\n",
    "    idx_dense_scores=np.argsort(dense_score_df)[:, :-k_prime-1:-1]\n",
    "\n",
    "    concat_idx=np.concatenate((idx_sparse_scores, idx_dense_scores), axis=1)\n",
    "    union_idx=[np.unique(x) for x in concat_idx]\n",
    "    idx_approx_top_k=np.asarray([union_idx[i][np.argsort(total_score_df.iloc[i, union_idx[i]])[:-k-1:-1].values]\n",
    "                    for i in range(len(union_idx))])\n",
    "    top_k_approx_docs=np.array(total_score_df.columns[idx_approx_top_k.reshape(-1)]).reshape(-1, k)\n",
    "\n",
    "    return top_k_approx_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_recalls=[]\n",
    "for k_prime in range(k, len(corpus)+1):\n",
    "    top_k_approx_docs=compute_approx_retrieval(sparse_score_df, dense_score_df, total_score_df, k_prime)\n",
    "    \n",
    "    recall=[len(np.intersect1d(top_k_exact_docs[i], top_k_approx_docs[i], assume_unique=True))/k for i in range(len(top_k_exact_docs))]\n",
    "    mean_recalls.append(np.mean(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8797652147049738"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: FARE STEMMING"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lwmd_ass2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
