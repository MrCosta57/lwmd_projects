{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import words\n",
    "from nltk.stem import PorterStemmer\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"datasets/nfcorpus/corpus.jsonl\"\n",
    "threshold=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs=pd.read_json(dataset, lines=True)\n",
    "df_docs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sk-learn's \"TfidfVectorizer\" and \"CountVectorizer\" extension to provide the stemming feature\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    stemmer = PorterStemmer()\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedTfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (StemmedTfidfVectorizer.stemmer.stem(w) for w in analyzer(doc))\n",
    "    \n",
    "    \n",
    "def compute_sparse_repr(vocab: np.array, corpus: pd.DataFrame):\n",
    "    #Extract only the word and the numbers, made a lowercase transformation and usage of custom vocabulary to make representations independent\n",
    "    doc_tfidf=StemmedTfidfVectorizer(lowercase=True, vocabulary=vocab, stop_words=None, token_pattern=r'\\w+')\n",
    "\n",
    "    #Computation of the sparse embedding\n",
    "    sparse_doc=doc_tfidf.fit_transform(corpus[\"text\"])\n",
    "\n",
    "    return sparse_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stem the vocabulary and drop the duplicates\n",
    "stemmer=PorterStemmer()\n",
    "vocab=np.unique([stemmer.stem(w) for w in np.char.lower(words.words())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_repr=compute_sparse_repr(vocab, df_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_scores=cosine_similarity(sparse_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(cosine_scores, -1)\n",
    "tmp=pd.DataFrame(cosine_scores, columns=df_docs[\"_id\"], index=df_docs[\"_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y=np.where(tmp>=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in zip(tmp.index[x], tmp.columns[y]):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" def evaluation_fun(total_score_df: pd.DataFrame, \n",
    "                   idx_sparse: np.array, idx_dense: np.array, idx_total: np.array,                   \n",
    "                   corpus_len: int, k_list: list, step:int=1, epsilon:float=0.01):\n",
    "    mean_recalls_list=[list() for i in range(len(k_list))]\n",
    "    top_k_exact_approx_lists=[list() for i in range(len(k_list))]\n",
    "    max_k_prime_list=[]\n",
    "    i=0\n",
    "    for k in k_list:\n",
    "        top_k_exact_docs=compute_exact_retrieval(total_score_df, idx_total, k)\n",
    "        for k_prime in range(k, corpus_len+1, step):\n",
    "            top_k_approx_docs=compute_approx_retrieval(idx_sparse, idx_dense, total_score_df, k, k_prime)\n",
    "            recalls=[len(np.intersect1d(top_k_exact_docs[i], top_k_approx_docs[i], assume_unique=True))/k for i in range(len(top_k_exact_docs))]\n",
    "            mean=np.mean(recalls)\n",
    "            mean_recalls_list[i].append(mean)\n",
    "\n",
    "            if mean>=1-epsilon or k==corpus_len:\n",
    "                print(k_prime)\n",
    "                max_k_prime_list.append(k_prime)\n",
    "                break\n",
    "        i+=1\n",
    "    \n",
    "    return mean_recalls_list, top_k_exact_approx_lists, max_k_prime_list\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" def print_plot(k_list, mean_recalls_list, max_k_prime_list, step=1):\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.ylabel('Recall scores')\n",
    "    plt.xlabel('K\\' values')\n",
    "    plt.ylim(np.min(np.concatenate(mean_recalls_list)), 1)\n",
    "    plt.hlines(np.max(np.concatenate(mean_recalls_list)), np.min(k_list), np.max(max_k_prime_list), linewidth=2, linestyles=\"dashed\", colors=\"grey\")\n",
    "\n",
    "    for i in range(len(k_list)):    \n",
    "        plt.plot(range(k_list[i], max_k_prime_list[i]+1, step), mean_recalls_list[i], linewidth=2, label=\"k=\"+str(k_list[i]))\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show() \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
