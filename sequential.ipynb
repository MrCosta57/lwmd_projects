{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning with Massive Data\n",
    "<p>\n",
    "Assignment 3 - Similarity search for document pairs<br>\n",
    "Giovanni Costa - 880892\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents:\n",
    "- [Document sparse representation](#doc_repr)\n",
    "- [Sequential Implementation](#s_impl)\n",
    "    - [Exact similarity search](#exact_s)\n",
    "    - [Approximate similarity search](#approx_s)\n",
    "- [Evaluations](#eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from scipy.sparse import load_npz, save_npz\n",
    "from nltk.corpus import words\n",
    "from nltk.stem import PorterStemmer\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
    "from sklearn.random_projection import SparseRandomProjection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"doc_repr\"></a>\n",
    "## Document sparse representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=\"datasets/nfcorpus/corpus.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3633 entries, 0 to 3632\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   _id       3633 non-null   object\n",
      " 1   title     3633 non-null   object\n",
      " 2   text      3633 non-null   object\n",
      " 3   metadata  3633 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 113.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_docs=pd.read_json(dataset, lines=True)\n",
    "df_docs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MED-10</td>\n",
       "      <td>Statin Use and Breast Cancer Survival: A Natio...</td>\n",
       "      <td>Recent studies have suggested that statins, an...</td>\n",
       "      <td>{'url': 'http://www.ncbi.nlm.nih.gov/pubmed/25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MED-14</td>\n",
       "      <td>Statin use after diagnosis of breast cancer an...</td>\n",
       "      <td>BACKGROUND: Preclinical studies have shown tha...</td>\n",
       "      <td>{'url': 'http://www.ncbi.nlm.nih.gov/pubmed/25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MED-118</td>\n",
       "      <td>Alkylphenols in human milk and their relations...</td>\n",
       "      <td>The aims of this study were to determine the c...</td>\n",
       "      <td>{'url': 'http://www.ncbi.nlm.nih.gov/pubmed/20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       _id                                              title  \\\n",
       "0   MED-10  Statin Use and Breast Cancer Survival: A Natio...   \n",
       "1   MED-14  Statin use after diagnosis of breast cancer an...   \n",
       "2  MED-118  Alkylphenols in human milk and their relations...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Recent studies have suggested that statins, an...   \n",
       "1  BACKGROUND: Preclinical studies have shown tha...   \n",
       "2  The aims of this study were to determine the c...   \n",
       "\n",
       "                                            metadata  \n",
       "0  {'url': 'http://www.ncbi.nlm.nih.gov/pubmed/25...  \n",
       "1  {'url': 'http://www.ncbi.nlm.nih.gov/pubmed/25...  \n",
       "2  {'url': 'http://www.ncbi.nlm.nih.gov/pubmed/20...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_docs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sk-learn's \"TfidfVectorizer\" extension to provide the stemming feature\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    stemmer = PorterStemmer()\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedTfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (StemmedTfidfVectorizer.stemmer.stem(w) for w in analyzer(doc))\n",
    "    \n",
    "    \n",
    "def compute_sparse_repr(corpus: pd.DataFrame):\n",
    "    #Extract only the word and the numbers, made a lowercase transformation and usage of custom vocabulary to make representations independent\n",
    "    doc_tfidf=StemmedTfidfVectorizer(lowercase=True, stop_words=None, token_pattern=r'\\w+', binary=True)\n",
    "\n",
    "    #Computation of the sparse embedding\n",
    "    sparse_doc=doc_tfidf.fit_transform(corpus[\"text\"])\n",
    "    vocab=doc_tfidf.vocabulary_\n",
    "    \n",
    "    return sparse_doc, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_repr, vocab=compute_sparse_repr(df_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pairs = sorted(vocab.items(), key=lambda x: x[1])\n",
    "vocab_terms = [pair[0] for pair in sorted_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(vocab_terms, columns=[\"terms\"]).to_parquet(\"terms_nfcorpus.parquet\")\n",
    "pd.DataFrame(df_docs[\"_id\"]).to_parquet(\"ids_nfcorpus.parquet\")\n",
    "save_npz(\"sparse_repr_nfcorpus.npz\", sparse_repr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"s_impl\"></a>\n",
    "## Sequential Implementation\n",
    "<a id=\"exact_s\"></a>\n",
    "### Exact similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3633, 18867)\n",
      "Density ratio: 0.006536315875404127\n"
     ]
    }
   ],
   "source": [
    "sparse_repr=load_npz(\"sparse_repr_nfcorpus.npz\")\n",
    "print(sparse_repr.shape)\n",
    "print(\"Density ratio:\", sparse_repr.count_nonzero()/(sparse_repr.shape[0]*sparse_repr.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "cosine_scores=cosine_similarity(sparse_repr)\n",
    "np.fill_diagonal(cosine_scores, -1)\n",
    "num_of_pairs=(cosine_scores>=threshold).sum()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_of_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "#tmp=pd.DataFrame(cosine_scores, columns=df_docs[\"_id\"], index=df_docs[\"_id\"])\n",
    "x, y=np.where(tmp>=0.5)\n",
    "for i, j in zip(tmp.index[x], tmp.columns[y]):\n",
    "    print(i, j) \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"approx_s\"></a>\n",
    "### Approximate similarity search\n",
    "(using Sparse Random Projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_proj=SparseRandomProjection(eps=epsilon, random_state=32)\n",
    "sr_proj.fit(sparse_repr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sr_proj.n_components_)\n",
    "print(sr_proj.density_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_repr_approx_srp=sr_proj.transform(sparse_repr)\n",
    "print(sparse_repr_approx_srp.shape)\n",
    "print(\"Density ratio:\", sparse_repr_approx_srp.count_nonzero()/(sparse_repr_approx_srp.shape[0]*sparse_repr_approx_srp.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "sparse_repr_approx_srp=sr_proj.transform(sparse_repr)\n",
    "cosine_scores_approx_srp=cosine_similarity(sparse_repr_approx_srp, dense_output=False)\n",
    "np.fill_diagonal(cosine_scores_approx_srp, -1)\n",
    "num_of_pairs_approx_srp=(cosine_scores_approx_srp>=threshold).sum()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_pairs_approx_srp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eval\"></a>\n",
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" def evaluation_fun(total_score_df: pd.DataFrame, \n",
    "                   idx_sparse: np.array, idx_dense: np.array, idx_total: np.array,                   \n",
    "                   corpus_len: int, k_list: list, step:int=1, epsilon:float=0.01):\n",
    "    mean_recalls_list=[list() for i in range(len(k_list))]\n",
    "    top_k_exact_approx_lists=[list() for i in range(len(k_list))]\n",
    "    max_k_prime_list=[]\n",
    "    i=0\n",
    "    for k in k_list:\n",
    "        top_k_exact_docs=compute_exact_retrieval(total_score_df, idx_total, k)\n",
    "        for k_prime in range(k, corpus_len+1, step):\n",
    "            top_k_approx_docs=compute_approx_retrieval(idx_sparse, idx_dense, total_score_df, k, k_prime)\n",
    "            recalls=[len(np.intersect1d(top_k_exact_docs[i], top_k_approx_docs[i], assume_unique=True))/k for i in range(len(top_k_exact_docs))]\n",
    "            mean=np.mean(recalls)\n",
    "            mean_recalls_list[i].append(mean)\n",
    "\n",
    "            if mean>=1-epsilon or k==corpus_len:\n",
    "                print(k_prime)\n",
    "                max_k_prime_list.append(k_prime)\n",
    "                break\n",
    "        i+=1\n",
    "    \n",
    "    return mean_recalls_list, top_k_exact_approx_lists, max_k_prime_list\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" def print_plot(k_list, mean_recalls_list, max_k_prime_list, step=1):\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.ylabel('Recall scores')\n",
    "    plt.xlabel('K\\' values')\n",
    "    plt.ylim(np.min(np.concatenate(mean_recalls_list)), 1)\n",
    "    plt.hlines(np.max(np.concatenate(mean_recalls_list)), np.min(k_list), np.max(max_k_prime_list), linewidth=2, linestyles=\"dashed\", colors=\"grey\")\n",
    "\n",
    "    for i in range(len(k_list)):    \n",
    "        plt.plot(range(k_list[i], max_k_prime_list[i]+1, step), mean_recalls_list[i], linewidth=2, label=\"k=\"+str(k_list[i]))\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show() \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
